# DevMate Configuration
# Copy to .env and configure

# Model Provider (bedrock, anthropic, ollama, openai)
MODEL_PROVIDER=bedrock

# AWS Configuration
AWS_PROFILE=default
AWS_REGION=us-west-2
AWS_ACCESS_KEY_ID=your_access_key_here
AWS_SECRET_ACCESS_KEY=your_secret_key_here
BEDROCK_MODEL_ID=us.amazon.nova-pro-v1:0

# Alternative APIs
ANTHROPIC_API_KEY=your_anthropic_key_here
OPENAI_API_KEY=your_openai_key_here

# Ollama Configuration
OLLAMA_HOST=http://localhost:11434
OLLAMA_MODEL=codellama

# Development Settings
PROJECT_ROOT=.
MAX_FILE_SIZE_MB=10
ANALYSIS_TIMEOUT=300

# External APIs
STACK_OVERFLOW_API_KEY=your_so_key_here
GITHUB_API_TOKEN=your_github_token_here
